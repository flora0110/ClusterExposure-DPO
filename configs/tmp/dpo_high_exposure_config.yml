base_model: HuggingFaceTB/SmolLM2-1.7B-Instruct
dpo:
  beta: 0.1
  bf16: true
  early_stopping_patience: 2
  evaluation_strategy: epoch
  gradient_accumulation_steps: 4
  learning_rate: 1e-5
  load_best_model_at_end: true
  logging_steps: 1
  loss_threshold: 0.05
  max_length: 512
  max_prompt_length: 512
  num_train_epochs: 1
  optim: adamw_torch
  per_device_eval_batch_size: 2
  per_device_train_batch_size: 2
  save_strategy: epoch
  save_total_limit: 1
  warmup_steps: 20
output_dir: /scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/ClusterExposure_model/Div_10_1.0/high_exposure
resume_from_checkpoint: /scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/sft_model/final_model
train_data_path: /scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/data/beam_cd_candidates/Div_10_1.0/high_exposure/train.json
valid_data_path: /scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/data/beam_cd_candidates/Div_10_1.0/high_exposure/valid.json
