# Softmax DPO training configuration

# Model and checkpoint
model_name: "HuggingFaceTB/SmolLM2-1.7B-Instruct"
resume_from_checkpoint: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/sft_model/final_model"

# Dataset paths
train_data_path: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/data/beam_cd_candidates/Div_10_1.0/train.json"
valid_data_path: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/data/beam_cd_candidates/Div_10_1.0/valid.json"
book2idx: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/lightgcn/models/book2idx_full_data_with_output.json"
item_emb: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/lightgcn/models/lightgcn_model_full_data_with_output.npy"
# Input and output directories
# Output
output_dir: ""

# Training hyperparameters
beta: 0.1
batch_size: 1
gradient_accumulation_steps: 8
num_train_epochs: 1
learning_rate: 1e-5
bf16: true
logging_steps: 1
max_neg: 5
distance_type: "dpc"
min_beta: 0.075
max_beta: 1.025

# Optional settings
num_proc: 8
max_valid: 2000