# Softmax DPO training configuration

# Model and checkpoint
model_name: "HuggingFaceTB/SmolLM2-1.7B-Instruct"
resume_from_checkpoint: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/sft_model/final_model"


# Dataset paths
train_data_path: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/data/beam_cd_candidates/Div_10_1.0/train.json"
valid_data_path: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/data/beam_cd_candidates/Div_10_1.0/valid.json"

# Output
tuned_model: "S-DPO"
method: "Div_5_1.0_epoch_1_beta_0.11"
base_output_dir: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/"
output_dir: ""

# Training hyperparameters
beta: 0.11
batch_size: 1
gradient_accumulation_steps: 8
num_train_epochs: 1
learning_rate: 1e-5
bf16: true
logging_steps: 1
max_neg: 5

# Optional settings
num_proc: 8
max_valid: 2000