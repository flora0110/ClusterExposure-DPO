# Model and checkpoint settings
base_model: "HuggingFaceTB/SmolLM2-1.7B-Instruct"
resume_from_checkpoint: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/sft_model/final_model"
# SPRec
# output_dir: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/experiments/model/SPRec_model"
output_dir: "/scratch/user/chuanhsin0110/test_0321/nlp/models/final"

# Data files (JSON lines format)
# train_data_path: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/data/negatives/selfplay/train.json"
# valid_data_path: "/scratch/user/chuanhsin0110/ClusterExposure-DPO/data/negatives/selfplay/valid.json"
train_data_path: "/scratch/user/chuanhsin0110/test_0321/nlp/dpo_data/train.json"
valid_data_path: "/scratch/user/chuanhsin0110/test_0321/nlp/dpo_data/valid.json"

# DPO training parameters
dpo:
  beta: 0.1
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 4
  warmup_steps: 20
  num_train_epochs: 1
  learning_rate: 1e-5
  bf16: true
  logging_steps: 1
  optim: "adamw_torch"
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 1
  load_best_model_at_end: true
  max_prompt_length: 512
  max_length: 512
  early_stopping_patience: 2
  loss_threshold: 0.05
